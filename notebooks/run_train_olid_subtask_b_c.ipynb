{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_train_olid_subtask_b_c.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuk6xBnn/sXNoDbUB53FTx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7AQt2WFs_HG","executionInfo":{"status":"ok","timestamp":1652202971569,"user_tz":240,"elapsed":21944,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"2473a9bb-dc81-4deb-b610-67e8f97039c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKmakm7FtxZN","executionInfo":{"status":"ok","timestamp":1652202980684,"user_tz":240,"elapsed":9119,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"068a5dc2-47c2-4654-97d5-57438b8226a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 61.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 62.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=8850f70074398712cf1e48e99b6f049e3664d0cd1f4cdec1612235f7c829f5c1\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hr9sYnvus9VG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652204953900,"user_tz":240,"elapsed":1733482,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"9f711044-3648-4fc6-ae5b-ab4d0c837d11"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/src/bert_finetuned/ckpts_OLID/english_subtask_b created!\n","Downloading: 100% 28.0/28.0 [00:00<00:00, 32.5kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 523kB/s]\n","Downloading: 100% 226k/226k [00:00<00:00, 428kB/s]\n","Downloading: 100% 455k/455k [00:00<00:00, 517kB/s]\n","Downloading: 100% 420M/420M [00:06<00:00, 73.3MB/s]\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","======== Epoch 1 / 50 ========\n","Training...\n","Total loss: 0.75215744972229 Train Acc: 0.26590909090909093\n","Validation Loss: 1.4867386519908905: Acc: 0.12916666666666668\n","Validation Precision:0.8333333333333334 Recall: 0.023474178403755867 F1: 0.045662100456621\n","best epoch: 1 best f1: 0.045662100456621\n","0.8333333333333334\t0.023474178403755867\t0.045662100456621\t0.12916666666666668\n","======== Epoch 2 / 50 ========\n","Training...\n","Total loss: 0.4186269185249356 Train Acc: 0.8477272727272728\n","Validation Loss: 0.6455337852239609: Acc: 0.8875\n","Validation Precision:0.8875 Recall: 1.0 F1: 0.9403973509933775\n","best epoch: 2 best f1: 0.9403973509933775\n","0.8875\t1.0\t0.9403973509933775\t0.8875\n","======== Epoch 3 / 50 ========\n","Training...\n","Total loss: 0.3491399895021881 Train Acc: 0.8809090909090909\n","Validation Loss: 0.5933831036090851: Acc: 0.8875\n","Validation Precision:0.8875 Recall: 1.0 F1: 0.9403973509933775\n","\n","======== Epoch 4 / 50 ========\n","Training...\n","Total loss: 0.3294563919737719 Train Acc: 0.8813636363636363\n","Validation Loss: 0.5527790784835815: Acc: 0.8875\n","Validation Precision:0.8875 Recall: 1.0 F1: 0.9403973509933775\n","\n","======== Epoch 5 / 50 ========\n","Training...\n","Total loss: 0.2959752255591793 Train Acc: 0.8831818181818182\n","Validation Loss: 0.5395562127232552: Acc: 0.8958333333333334\n","Validation Precision:0.908695652173913 Recall: 0.9812206572769953 F1: 0.9435665914221218\n","best epoch: 5 best f1: 0.9435665914221218\n","0.908695652173913\t0.9812206572769953\t0.9435665914221218\t0.8958333333333334\n","======== Epoch 6 / 50 ========\n","Training...\n","Total loss: 0.24185038465952527 Train Acc: 0.8997727272727273\n","Validation Loss: 0.5014410838484764: Acc: 0.9041666666666667\n","Validation Precision:0.9357798165137615 Recall: 0.9577464788732394 F1: 0.9466357308584686\n","best epoch: 6 best f1: 0.9466357308584686\n","0.9357798165137615\t0.9577464788732394\t0.9466357308584686\t0.9041666666666667\n","======== Epoch 7 / 50 ========\n","Training...\n","Total loss: 0.16496263730569163 Train Acc: 0.9420454545454545\n","Validation Loss: 0.6949037909507751: Acc: 0.8625\n","Validation Precision:0.9166666666666666 Recall: 0.9295774647887324 F1: 0.9230769230769231\n","\n","======== Epoch 8 / 50 ========\n","Training...\n","Total loss: 0.10494134002837582 Train Acc: 0.9672727272727273\n","Validation Loss: 0.7945909351110458: Acc: 0.8791666666666667\n","Validation Precision:0.9181818181818182 Recall: 0.9483568075117371 F1: 0.9330254041570438\n","\n","======== Epoch 9 / 50 ========\n","Training...\n","Total loss: 0.0681124642437351 Train Acc: 0.9797727272727272\n","Validation Loss: 0.8371050655841827: Acc: 0.8958333333333334\n","Validation Precision:0.915929203539823 Recall: 0.971830985915493 F1: 0.9430523917995445\n","\n","======== Epoch 10 / 50 ========\n","Training...\n","Total loss: 0.04783084065369938 Train Acc: 0.9852272727272727\n","Validation Loss: 0.8806797116994858: Acc: 0.9\n","Validation Precision:0.92 Recall: 0.971830985915493 F1: 0.9452054794520549\n","\n","======== Epoch 11 / 50 ========\n","Training...\n","Total loss: 0.03116990626533178 Train Acc: 0.990909090909091\n","Validation Loss: 1.0096763521432877: Acc: 0.875\n","Validation Precision:0.9178082191780822 Recall: 0.9436619718309859 F1: 0.9305555555555556\n","\n","======== Epoch 12 / 50 ========\n","Training...\n","Total loss: 0.02824745685590998 Train Acc: 0.9918181818181818\n","Validation Loss: 0.9926518052816391: Acc: 0.8958333333333334\n","Validation Precision:0.9272727272727272 Recall: 0.9577464788732394 F1: 0.9422632794457274\n","\n","======== Epoch 13 / 50 ========\n","Training...\n","Total loss: 0.02748684873264553 Train Acc: 0.9897727272727272\n","Validation Loss: 1.1905056536197662: Acc: 0.9\n","Validation Precision:0.9090909090909091 Recall: 0.9859154929577465 F1: 0.9459459459459459\n","\n","======== Epoch 14 / 50 ========\n","Training...\n","Total loss: 0.018434377716165847 Train Acc: 0.9945454545454545\n","Validation Loss: 1.1227364391088486: Acc: 0.8958333333333334\n","Validation Precision:0.9234234234234234 Recall: 0.9624413145539906 F1: 0.942528735632184\n","\n","======== Epoch 15 / 50 ========\n","Training...\n","Total loss: 0.01645150541267155 Train Acc: 0.9945454545454545\n","Validation Loss: 1.1168963611125946: Acc: 0.8833333333333333\n","Validation Precision:0.9111111111111111 Recall: 0.9624413145539906 F1: 0.9360730593607306\n","\n","======== Epoch 16 / 50 ========\n","Training...\n","Total loss: 0.014919179847693422 Train Acc: 0.9947727272727273\n","Validation Loss: 1.1204347014427185: Acc: 0.875\n","Validation Precision:0.9463414634146341 Recall: 0.9107981220657277 F1: 0.9282296650717704\n","\n","======== Epoch 17 / 50 ========\n","Training...\n","Total loss: 0.01993075683982908 Train Acc: 0.9931818181818182\n","Validation Loss: 1.2802470326423645: Acc: 0.8958333333333334\n","Validation Precision:0.908695652173913 Recall: 0.9812206572769953 F1: 0.9435665914221218\n","\n","======== Epoch 18 / 50 ========\n","Training...\n","Total loss: 0.013350343482697086 Train Acc: 0.9947727272727273\n","Validation Loss: 1.2508644461631775: Acc: 0.8833333333333333\n","Validation Precision:0.9223744292237442 Recall: 0.9483568075117371 F1: 0.9351851851851852\n","\n","======== Epoch 19 / 50 ========\n","Training...\n","Total loss: 0.011909781680172444 Train Acc: 0.995\n","Validation Loss: 1.3252518773078918: Acc: 0.875\n","Validation Precision:0.9255813953488372 Recall: 0.9342723004694836 F1: 0.9299065420560748\n","\n","======== Epoch 20 / 50 ========\n","Training...\n","Total loss: 0.012624127881439485 Train Acc: 0.9943181818181818\n","Validation Loss: 1.2750552743673325: Acc: 0.875\n","Validation Precision:0.9216589861751152 Recall: 0.9389671361502347 F1: 0.930232558139535\n","\n","======== Epoch 21 / 50 ========\n","Training...\n","Total loss: 0.011383198760534246 Train Acc: 0.9952272727272727\n","Validation Loss: 1.408465564250946: Acc: 0.9\n","Validation Precision:0.92 Recall: 0.971830985915493 F1: 0.9452054794520549\n","\n","======== Epoch 22 / 50 ========\n","Training...\n","Total loss: 0.011096179163069937 Train Acc: 0.9947727272727273\n","Validation Loss: 1.363539457321167: Acc: 0.8958333333333334\n","Validation Precision:0.915929203539823 Recall: 0.971830985915493 F1: 0.9430523917995445\n","\n","======== Epoch 23 / 50 ========\n","Training...\n","Total loss: 0.008696535128114772 Train Acc: 0.9954545454545455\n","Validation Loss: 1.345282033085823: Acc: 0.8833333333333333\n","Validation Precision:0.9223744292237442 Recall: 0.9483568075117371 F1: 0.9351851851851852\n","\n","======== Epoch 24 / 50 ========\n","Training...\n","Total loss: 0.010078606592234817 Train Acc: 0.995\n","Validation Loss: 1.4351800680160522: Acc: 0.9\n","Validation Precision:0.9162995594713657 Recall: 0.9765258215962441 F1: 0.9454545454545455\n","\n","======== Epoch 25 / 50 ========\n","Training...\n","Total loss: 0.011222865772889118 Train Acc: 0.9947727272727273\n","Validation Loss: 1.4104660004377365: Acc: 0.8916666666666667\n","Validation Precision:0.9082969432314411 Recall: 0.9765258215962441 F1: 0.9411764705882353\n","\n","======== Epoch 26 / 50 ========\n","Training...\n","Total loss: 0.010284593574318063 Train Acc: 0.9947727272727273\n","Validation Loss: 1.262150138616562: Acc: 0.9\n","Validation Precision:0.9315068493150684 Recall: 0.9577464788732394 F1: 0.9444444444444444\n","\n","======== Epoch 27 / 50 ========\n","Training...\n","Total loss: 0.00853969606206469 Train Acc: 0.9954545454545455\n","Validation Loss: 1.3817942291498184: Acc: 0.8958333333333334\n","Validation Precision:0.915929203539823 Recall: 0.971830985915493 F1: 0.9430523917995445\n","\n","======== Epoch 28 / 50 ========\n","Training...\n","Total loss: 0.011181142737926997 Train Acc: 0.9947727272727273\n","Validation Loss: 1.3114515393972397: Acc: 0.9\n","Validation Precision:0.9162995594713657 Recall: 0.9765258215962441 F1: 0.9454545454545455\n","\n","======== Epoch 29 / 50 ========\n","Training...\n","Total loss: 0.009413444114835474 Train Acc: 0.9947727272727273\n","Validation Loss: 1.3000362515449524: Acc: 0.9083333333333333\n","Validation Precision:0.920704845814978 Recall: 0.9812206572769953 F1: 0.95\n","best epoch: 29 best f1: 0.95\n","0.920704845814978\t0.9812206572769953\t0.95\t0.9083333333333333\n","======== Epoch 30 / 50 ========\n","Training...\n","Total loss: 0.007209109136095756 Train Acc: 0.9965909090909091\n","Validation Loss: 1.306023195385933: Acc: 0.8958333333333334\n","Validation Precision:0.9234234234234234 Recall: 0.9624413145539906 F1: 0.942528735632184\n","\n","======== Epoch 31 / 50 ========\n","Training...\n","Total loss: 0.007660004237761208 Train Acc: 0.9959090909090909\n","Validation Loss: 1.4426002502441406: Acc: 0.9\n","Validation Precision:0.9090909090909091 Recall: 0.9859154929577465 F1: 0.9459459459459459\n","\n","======== Epoch 32 / 50 ========\n","Training...\n","Total loss: 0.00832410283075423 Train Acc: 0.9963636363636363\n","Validation Loss: 1.3212848007678986: Acc: 0.8791666666666667\n","Validation Precision:0.9259259259259259 Recall: 0.9389671361502347 F1: 0.9324009324009325\n","\n","======== Epoch 33 / 50 ========\n","Training...\n","Total loss: 0.006403532429206846 Train Acc: 0.9979545454545454\n","Validation Loss: 1.3670480847358704: Acc: 0.8958333333333334\n","Validation Precision:0.9234234234234234 Recall: 0.9624413145539906 F1: 0.942528735632184\n","\n","======== Epoch 34 / 50 ========\n","Training...\n","Total loss: 0.005767119316379135 Train Acc: 0.9981818181818182\n","Validation Loss: 1.4211099445819855: Acc: 0.8791666666666667\n","Validation Precision:0.9220183486238532 Recall: 0.9436619718309859 F1: 0.9327146171693735\n","\n","======== Epoch 35 / 50 ========\n","Training...\n","Total loss: 0.006278226231992501 Train Acc: 0.9977272727272727\n","Validation Loss: 1.3950721323490143: Acc: 0.8958333333333334\n","Validation Precision:0.9234234234234234 Recall: 0.9624413145539906 F1: 0.942528735632184\n","\n","======== Epoch 36 / 50 ========\n","Training...\n","Total loss: 0.006490814210838585 Train Acc: 0.9979545454545454\n","Validation Loss: 1.4384616613388062: Acc: 0.9\n","Validation Precision:0.92 Recall: 0.971830985915493 F1: 0.9452054794520549\n","\n","======== Epoch 37 / 50 ========\n","Training...\n","Total loss: 0.00642802493108531 Train Acc: 0.9972727272727273\n","Validation Loss: 1.4420428276062012: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 38 / 50 ========\n","Training...\n","Total loss: 0.005527124692942353 Train Acc: 0.9984090909090909\n","Validation Loss: 1.455786556005478: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 39 / 50 ========\n","Training...\n","Total loss: 0.004878459569253197 Train Acc: 0.9986363636363637\n","Validation Loss: 1.467310905456543: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 40 / 50 ========\n","Training...\n","Total loss: 0.004960451601790197 Train Acc: 0.9981818181818182\n","Validation Loss: 1.4611430764198303: Acc: 0.8958333333333334\n","Validation Precision:0.9234234234234234 Recall: 0.9624413145539906 F1: 0.942528735632184\n","\n","======== Epoch 41 / 50 ========\n","Training...\n","Total loss: 0.004732683667300634 Train Acc: 0.9981818181818182\n","Validation Loss: 1.4937704801559448: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 42 / 50 ========\n","Training...\n","Total loss: 0.004413128495587549 Train Acc: 0.9984090909090909\n","Validation Loss: 1.500508427619934: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 43 / 50 ========\n","Training...\n","Total loss: 0.004628148614479553 Train Acc: 0.9984090909090909\n","Validation Loss: 1.469977229833603: Acc: 0.8958333333333334\n","Validation Precision:0.9234234234234234 Recall: 0.9624413145539906 F1: 0.942528735632184\n","\n","======== Epoch 44 / 50 ========\n","Training...\n","Total loss: 0.0041004441198943505 Train Acc: 0.9984090909090909\n","Validation Loss: 1.4642122387886047: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 45 / 50 ========\n","Training...\n","Total loss: 0.004922629397196283 Train Acc: 0.9981818181818182\n","Validation Loss: 1.4795441031455994: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 46 / 50 ========\n","Training...\n","Total loss: 0.004235537527626771 Train Acc: 0.9984090909090909\n","Validation Loss: 1.505583018064499: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 47 / 50 ========\n","Training...\n","Total loss: 0.004273075985374685 Train Acc: 0.9986363636363637\n","Validation Loss: 1.5105498135089874: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 48 / 50 ========\n","Training...\n","Total loss: 0.004022455301837645 Train Acc: 0.9986363636363637\n","Validation Loss: 1.5098085701465607: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 49 / 50 ========\n","Training...\n","Total loss: 0.004386319799843899 Train Acc: 0.9986363636363637\n","Validation Loss: 1.509240835905075: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n","\n","======== Epoch 50 / 50 ========\n","Training...\n","Total loss: 0.003880003857151335 Train Acc: 0.9986363636363637\n","Validation Loss: 1.5113989412784576: Acc: 0.9\n","Validation Precision:0.9237668161434978 Recall: 0.9671361502347418 F1: 0.944954128440367\n"]}],"source":["!python /content/drive/MyDrive/src/bert_finetuned/bert_finetune_OLID.py \\\n","--language 'english' \\\n","--logs_dir '/content/drive/MyDrive/src/bert_finetuned/ckpts_OLID_subtask_b' \\\n","--batch_size 64 \\\n","--learning_rate 2e-5 \\\n","--weight_decay 1e-2 \\\n","--epochs 50 \\\n","--subtask 'subtask_b'"]},{"cell_type":"code","source":[""],"metadata":{"id":"ljyVsJ98_Gpt"},"execution_count":null,"outputs":[]}]}